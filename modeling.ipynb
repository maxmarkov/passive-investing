{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce7208a",
   "metadata": {},
   "source": [
    "# Stock index statistics\n",
    "\n",
    "This notebook shows how to compute stock index statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f8c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle \n",
    "from src.analyzer import StockIndexAnalyzer\n",
    "\n",
    "# load data\n",
    "FILEPATH = \"data/all_indexes_2006-01-01_2021-12-31.pickle\"\n",
    "with open(FILEPATH, \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "# define groups of indexes\n",
    "indexes_usa = ['SPX','CCMP','RIY','RTY','RAY','RLV','RLG','NBI']\n",
    "indexes_sp500 = ['S5COND','S5CONS','S5ENRS','S5FINL','S5HLTH','S5INFT','S5MATR','S5TELS','S5UTIL','S5INDU']#'S5RLST'\n",
    "indexes_eu = ['DAX','CAC','UKX','BEL20','IBEX','KFX','OMX','SMI']\n",
    "indexes_apac = ['AS51'] #,'HSI','STI']\n",
    "indexes_jp = ['NKY','TPX']\n",
    "indexes_bric = ['IBOV','NIFTY','MXIN','SHCOMP','SHSZ300'] #'RTSI$'\n",
    "\n",
    "# merge all groups into one\n",
    "indexes_all = indexes_usa + indexes_sp500 + indexes_eu + indexes_apac + indexes_jp + indexes_bric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8edefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = data['RTSI$']#['0118440Q UQ']\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c620f91",
   "metadata": {},
   "source": [
    "Loop over all indexes to compute empirical statistics (mean, median and mode). The resuts are saved into dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed096e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2006-12-29\"\n",
    "end_date = \"2021-12-31\"\n",
    "\n",
    "results_expt = {}   # histogram statistics \n",
    "results_mcmc = {}   # fit histogram with MCMC\n",
    "results_scipy = {}  # fit histogram with scipy\n",
    "\n",
    "for index_name in indexes_all:\n",
    "    \n",
    "    print(f\"Processing {index_name} index\")\n",
    "    \n",
    "    stock_analyzer = StockIndexAnalyzer(prices = data[index_name],\n",
    "                                        stock_index = index_name,\n",
    "                                        start_date = start_date,\n",
    "                                        end_date = end_date)\n",
    "    \n",
    "    ### Part 1. Compute empirical stock index distribution parameter ###\n",
    "    #stock_analyzer.plot_histogram()\n",
    "    stock_analyzer.plot_histogram_fit(save_data=False)\n",
    "\n",
    "    results_expt[index_name] = {'category': stock_analyzer.category,\n",
    "                           'years': stock_analyzer.nyears,\n",
    "                           'n_stocks': len(stock_analyzer.tickers),\n",
    "                           'n_stocks_data': len(stock_analyzer.mu),\n",
    "                           'mean': stock_analyzer.mean_expt,\n",
    "                           'median': stock_analyzer.median_expt,\n",
    "                           'mode': stock_analyzer.mode_expt,\n",
    "                           'mean/median': stock_analyzer.mean_expt/stock_analyzer.median_expt,\n",
    "                           'mean/mode': stock_analyzer.mean_expt/stock_analyzer.mode_expt}\n",
    "    \n",
    "    results_scipy[index_name] = stock_analyzer.compare_stats()\n",
    "    \n",
    "    ### Part 2: fit index histogram with MCMC ###\n",
    "    results_mcmc[index_name] = stock_analyzer.pymc3_fit(draws=10000, tune=5000)\n",
    "    \n",
    "    summary = stock_analyzer.find_best_distribution()\n",
    "    print(summary)\n",
    "    results_mcmc[index_name]['lognorm error'] = summary.loc['lognorm']['sumsquare_error']\n",
    "    results_mcmc[index_name]['best distr'] = summary.sort_values('sumsquare_error').iloc[0].name\n",
    "    results_mcmc[index_name]['best distr error'] = summary.sort_values('sumsquare_error').iloc[0]['sumsquare_error']\n",
    "    \n",
    "    ### Part 3: estimate QQ plot\n",
    "    stock_analyzer.plot_qq()\n",
    "    stock_analyzer.plot_qq_seaborn()\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c8c13",
   "metadata": {},
   "source": [
    "Transform results dictionary into DataFrame. Transpose the table to have indexes as rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d215b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be rounded\n",
    "col_dec2 = ['logn mean','logn median','logn mode','logn mu','logn sigma','logn sigma2','C']\n",
    "\n",
    "df_scipy = pd.DataFrame.from_dict(results_scipy).T\n",
    "df_scipy[col_dec2] = df_scipy[col_dec2].astype(float).round(2)\n",
    "df_scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5039509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be rounded\n",
    "col_dec2 = ['logn mean','logn median','logn mode','logn mu','logn sigma','logn sigma2','C']\n",
    "col_dec3 = ['muh','sigmah','sigma']\n",
    "col_dec4 = ['lognorm error', 'best distr error']\n",
    "\n",
    "df_mcmc = pd.DataFrame.from_dict(results_mcmc).T\n",
    "df_mcmc = df_mcmc.drop(['muh std','sigma std', 'sigmah std'], axis=1)\n",
    "df_mcmc[col_dec2] = df_mcmc[col_dec2].astype(float).round(2)\n",
    "df_mcmc[col_dec3] = df_mcmc[col_dec3].astype(float).round(3)\n",
    "df_mcmc[col_dec4] = df_mcmc[col_dec4].astype(float).round(4)\n",
    "df_mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be rounded\n",
    "col_dec = ['mean','mode','median','mean/median','mean/mode']\n",
    "\n",
    "df_expt = pd.DataFrame.from_dict(results_expt).T\n",
    "df_expt[col_dec] = df_expt[col_dec].astype(float).round(2)\n",
    "df_expt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bfd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_expt.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012bb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mcmc.to_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930a007",
   "metadata": {},
   "source": [
    "Save dataframe with the results table into CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db22b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'results'\n",
    "os.makedirs(DIR, exist_ok=True)\n",
    "\n",
    "df_expt.to_csv(DIR+f'/data_emprirical_{stock_analyzer.nyears}.csv', header=True)\n",
    "df_mcmc.to_csv(DIR+f'/data_mcmc_{stock_analyzer.nyears}.csv', header=True)\n",
    "df_scipy.to_csv(DIR+f'/data_scipy_{stock_analyzer.nyears}.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin-stock",
   "language": "python",
   "name": "fin-stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
